{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from models.type import Type as ModelType\n",
    "from data.type import Type as DataType\n",
    "from results.results import Results\n",
    "from train.params import Params\n",
    "from train.builder import build_params\n",
    "\n",
    "import ssl\n",
    "\n",
    "from train.train_wgan import TrainWGan\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train WGan with Fashion-Mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args: {} = {}\n",
    "args[\"epochs\"] = 1 # number of epochs of training\n",
    "args[\"batch_size\"] = 64 # size of the batches\n",
    "args[\"lr\"] = 0.0002 # adam: learning rate\n",
    "args[\"b1\"] = 0.5 # adam: decay of first order momentum of gradient\n",
    "args[\"b2\"] = 0.999 # adam: decay of first order momentum of gradient\n",
    "args[\"latent_dim\"] = 100 # dimensionality of the latent space\n",
    "args[\"critic\"] = 5 # number of training steps for discriminator per iter\n",
    "args[\"gradient_penalty_lambda\"] = 10 # loss weight for gradient penalty\n",
    "args[\"save_generated_image_every\"] = 50 # interval batches between saving image\n",
    "\n",
    "params: Params = build_params(args, ModelType.WGAN_GP, DataType.FASHION_MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1] [Batch 1/938] [Discriminator loss: 7.965496] [Generator loss: 0.020921]\n",
      "[Epoch 1/1] [Batch 6/938] [Discriminator loss: 4.205560] [Generator loss: 0.005333]\n",
      "[Epoch 1/1] [Batch 11/938] [Discriminator loss: -4.479178] [Generator loss: -0.056411]\n",
      "[Epoch 1/1] [Batch 16/938] [Discriminator loss: -14.374399] [Generator loss: -0.213896]\n",
      "[Epoch 1/1] [Batch 21/938] [Discriminator loss: -20.077557] [Generator loss: -0.463803]\n",
      "[Epoch 1/1] [Batch 26/938] [Discriminator loss: -23.303551] [Generator loss: -0.658140]\n",
      "[Epoch 1/1] [Batch 31/938] [Discriminator loss: -26.219278] [Generator loss: -0.872584]\n",
      "[Epoch 1/1] [Batch 36/938] [Discriminator loss: -25.330536] [Generator loss: -1.083971]\n",
      "[Epoch 1/1] [Batch 41/938] [Discriminator loss: -24.415670] [Generator loss: -1.297791]\n",
      "[Epoch 1/1] [Batch 46/938] [Discriminator loss: -25.419647] [Generator loss: -1.563311]\n",
      "[Epoch 1/1] [Batch 51/938] [Discriminator loss: -25.345894] [Generator loss: -1.838504]\n",
      "[Epoch 1/1] [Batch 56/938] [Discriminator loss: -24.405600] [Generator loss: -2.116753]\n",
      "[Epoch 1/1] [Batch 61/938] [Discriminator loss: -24.209200] [Generator loss: -2.385070]\n",
      "[Epoch 1/1] [Batch 66/938] [Discriminator loss: -23.596617] [Generator loss: -2.747830]\n",
      "[Epoch 1/1] [Batch 71/938] [Discriminator loss: -23.669632] [Generator loss: -3.157532]\n",
      "[Epoch 1/1] [Batch 76/938] [Discriminator loss: -21.678682] [Generator loss: -3.591050]\n",
      "[Epoch 1/1] [Batch 81/938] [Discriminator loss: -21.678951] [Generator loss: -3.997033]\n",
      "[Epoch 1/1] [Batch 86/938] [Discriminator loss: -22.234631] [Generator loss: -4.581509]\n",
      "[Epoch 1/1] [Batch 91/938] [Discriminator loss: -20.907322] [Generator loss: -5.021252]\n",
      "[Epoch 1/1] [Batch 96/938] [Discriminator loss: -19.544605] [Generator loss: -5.476866]\n",
      "[Epoch 1/1] [Batch 101/938] [Discriminator loss: -21.229485] [Generator loss: -6.199122]\n",
      "[Epoch 1/1] [Batch 106/938] [Discriminator loss: -20.204666] [Generator loss: -6.495793]\n",
      "[Epoch 1/1] [Batch 111/938] [Discriminator loss: -19.556871] [Generator loss: -7.617456]\n",
      "[Epoch 1/1] [Batch 116/938] [Discriminator loss: -19.337070] [Generator loss: -7.995966]\n",
      "[Epoch 1/1] [Batch 121/938] [Discriminator loss: -17.551575] [Generator loss: -9.020689]\n",
      "[Epoch 1/1] [Batch 126/938] [Discriminator loss: -17.227655] [Generator loss: -9.480872]\n",
      "[Epoch 1/1] [Batch 131/938] [Discriminator loss: -17.233789] [Generator loss: -9.792230]\n",
      "[Epoch 1/1] [Batch 136/938] [Discriminator loss: -15.683953] [Generator loss: -10.776043]\n",
      "[Epoch 1/1] [Batch 141/938] [Discriminator loss: -14.478567] [Generator loss: -11.275318]\n",
      "[Epoch 1/1] [Batch 146/938] [Discriminator loss: -14.150986] [Generator loss: -11.763315]\n",
      "[Epoch 1/1] [Batch 151/938] [Discriminator loss: -12.319719] [Generator loss: -12.502201]\n",
      "[Epoch 1/1] [Batch 156/938] [Discriminator loss: -12.791087] [Generator loss: -11.455471]\n",
      "[Epoch 1/1] [Batch 161/938] [Discriminator loss: -11.473190] [Generator loss: -12.252110]\n",
      "[Epoch 1/1] [Batch 166/938] [Discriminator loss: -10.261439] [Generator loss: -11.561018]\n",
      "[Epoch 1/1] [Batch 171/938] [Discriminator loss: -9.900036] [Generator loss: -11.795770]\n",
      "[Epoch 1/1] [Batch 176/938] [Discriminator loss: -9.751775] [Generator loss: -11.001579]\n",
      "[Epoch 1/1] [Batch 181/938] [Discriminator loss: -9.520105] [Generator loss: -11.628725]\n",
      "[Epoch 1/1] [Batch 186/938] [Discriminator loss: -8.187036] [Generator loss: -12.783066]\n",
      "[Epoch 1/1] [Batch 191/938] [Discriminator loss: -6.765573] [Generator loss: -13.074606]\n",
      "[Epoch 1/1] [Batch 196/938] [Discriminator loss: -6.614480] [Generator loss: -12.407998]\n",
      "[Epoch 1/1] [Batch 201/938] [Discriminator loss: -6.667398] [Generator loss: -11.586868]\n",
      "[Epoch 1/1] [Batch 206/938] [Discriminator loss: -5.767817] [Generator loss: -13.278551]\n",
      "[Epoch 1/1] [Batch 211/938] [Discriminator loss: -5.199893] [Generator loss: -13.560903]\n",
      "[Epoch 1/1] [Batch 216/938] [Discriminator loss: -5.037541] [Generator loss: -13.683099]\n",
      "[Epoch 1/1] [Batch 221/938] [Discriminator loss: -4.790106] [Generator loss: -13.872068]\n",
      "[Epoch 1/1] [Batch 226/938] [Discriminator loss: -4.408297] [Generator loss: -13.751345]\n",
      "[Epoch 1/1] [Batch 231/938] [Discriminator loss: -5.284828] [Generator loss: -12.626862]\n",
      "[Epoch 1/1] [Batch 236/938] [Discriminator loss: -4.394081] [Generator loss: -11.174474]\n",
      "[Epoch 1/1] [Batch 241/938] [Discriminator loss: -4.367504] [Generator loss: -8.578096]\n",
      "[Epoch 1/1] [Batch 246/938] [Discriminator loss: -5.199994] [Generator loss: -8.837586]\n",
      "Generator Losses: [1, 6, 11, 16, 21, 26, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 106, 111, 116, 121, 126, 131, 136, 141, 146, 151, 156, 161, 166, 171, 176, 181, 186, 191, 196, 201, 206, 211, 216, 221, 226, 231, 236, 241, 246]\n",
      "Discriminator Losses: [1, 6, 11, 16, 21, 26, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 106, 111, 116, 121, 126, 131, 136, 141, 146, 151, 156, 161, 166, 171, 176, 181, 186, 191, 196, 201, 206, 211, 216, 221, 226, 231, 236, 241, 246]\n",
      "[Epoch 1/1] [Batch 251/938] [Discriminator loss: -4.634852] [Generator loss: -9.155351]\n",
      "[Epoch 1/1] [Batch 256/938] [Discriminator loss: -4.612856] [Generator loss: -8.288225]\n",
      "[Epoch 1/1] [Batch 261/938] [Discriminator loss: -5.219065] [Generator loss: -10.105125]\n",
      "[Epoch 1/1] [Batch 266/938] [Discriminator loss: -4.075647] [Generator loss: -9.235358]\n",
      "[Epoch 1/1] [Batch 271/938] [Discriminator loss: -5.036088] [Generator loss: -9.461564]\n",
      "[Epoch 1/1] [Batch 276/938] [Discriminator loss: -3.356856] [Generator loss: -9.853412]\n",
      "[Epoch 1/1] [Batch 281/938] [Discriminator loss: -1.708746] [Generator loss: -10.420107]\n",
      "[Epoch 1/1] [Batch 286/938] [Discriminator loss: -3.102496] [Generator loss: -10.316218]\n",
      "[Epoch 1/1] [Batch 291/938] [Discriminator loss: -2.217313] [Generator loss: -11.191255]\n",
      "[Epoch 1/1] [Batch 296/938] [Discriminator loss: -3.167744] [Generator loss: -9.846500]\n",
      "[Epoch 1/1] [Batch 301/938] [Discriminator loss: -2.285516] [Generator loss: -9.281141]\n",
      "[Epoch 1/1] [Batch 306/938] [Discriminator loss: -2.905499] [Generator loss: -9.614882]\n",
      "[Epoch 1/1] [Batch 311/938] [Discriminator loss: -3.269382] [Generator loss: -8.756281]\n",
      "[Epoch 1/1] [Batch 316/938] [Discriminator loss: -3.792183] [Generator loss: -7.888828]\n",
      "[Epoch 1/1] [Batch 321/938] [Discriminator loss: -3.934785] [Generator loss: -5.199209]\n",
      "[Epoch 1/1] [Batch 326/938] [Discriminator loss: -3.758099] [Generator loss: -4.412371]\n",
      "[Epoch 1/1] [Batch 331/938] [Discriminator loss: -5.091068] [Generator loss: -3.867783]\n",
      "[Epoch 1/1] [Batch 336/938] [Discriminator loss: -5.893026] [Generator loss: 0.098797]\n",
      "[Epoch 1/1] [Batch 341/938] [Discriminator loss: -6.073497] [Generator loss: 2.295290]\n",
      "[Epoch 1/1] [Batch 346/938] [Discriminator loss: -5.758837] [Generator loss: 5.668643]\n",
      "[Epoch 1/1] [Batch 351/938] [Discriminator loss: -5.582184] [Generator loss: 6.935976]\n",
      "[Epoch 1/1] [Batch 356/938] [Discriminator loss: -6.414783] [Generator loss: 3.887607]\n",
      "[Epoch 1/1] [Batch 361/938] [Discriminator loss: -4.683753] [Generator loss: 1.853311]\n",
      "[Epoch 1/1] [Batch 366/938] [Discriminator loss: -5.375467] [Generator loss: 2.691485]\n",
      "[Epoch 1/1] [Batch 371/938] [Discriminator loss: -4.356012] [Generator loss: 0.906354]\n",
      "[Epoch 1/1] [Batch 376/938] [Discriminator loss: -4.724367] [Generator loss: -0.951500]\n",
      "[Epoch 1/1] [Batch 381/938] [Discriminator loss: -4.977703] [Generator loss: -2.062259]\n",
      "[Epoch 1/1] [Batch 386/938] [Discriminator loss: -5.310471] [Generator loss: 0.471203]\n",
      "[Epoch 1/1] [Batch 391/938] [Discriminator loss: -5.155000] [Generator loss: -1.278047]\n",
      "[Epoch 1/1] [Batch 396/938] [Discriminator loss: -6.200689] [Generator loss: -2.777205]\n",
      "[Epoch 1/1] [Batch 401/938] [Discriminator loss: -5.207553] [Generator loss: -2.459055]\n",
      "[Epoch 1/1] [Batch 406/938] [Discriminator loss: -5.744671] [Generator loss: -0.360109]\n",
      "[Epoch 1/1] [Batch 411/938] [Discriminator loss: -5.332565] [Generator loss: -2.397189]\n",
      "[Epoch 1/1] [Batch 416/938] [Discriminator loss: -5.997226] [Generator loss: -3.198413]\n",
      "[Epoch 1/1] [Batch 421/938] [Discriminator loss: -5.695936] [Generator loss: -2.795923]\n",
      "[Epoch 1/1] [Batch 426/938] [Discriminator loss: -6.022577] [Generator loss: 1.204220]\n",
      "[Epoch 1/1] [Batch 431/938] [Discriminator loss: -5.593099] [Generator loss: -2.612114]\n",
      "[Epoch 1/1] [Batch 436/938] [Discriminator loss: -3.630378] [Generator loss: -1.936630]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1] [Batch 441/938] [Discriminator loss: -5.031691] [Generator loss: -2.401665]\n",
      "[Epoch 1/1] [Batch 446/938] [Discriminator loss: -5.067956] [Generator loss: -2.723453]\n",
      "[Epoch 1/1] [Batch 451/938] [Discriminator loss: -5.020389] [Generator loss: -1.595452]\n",
      "[Epoch 1/1] [Batch 456/938] [Discriminator loss: -5.884916] [Generator loss: -1.715223]\n",
      "[Epoch 1/1] [Batch 461/938] [Discriminator loss: -5.421385] [Generator loss: -1.258875]\n",
      "[Epoch 1/1] [Batch 466/938] [Discriminator loss: -4.142063] [Generator loss: -4.470121]\n",
      "[Epoch 1/1] [Batch 471/938] [Discriminator loss: -4.629319] [Generator loss: -4.465357]\n",
      "[Epoch 1/1] [Batch 476/938] [Discriminator loss: -5.577743] [Generator loss: -3.048803]\n",
      "[Epoch 1/1] [Batch 481/938] [Discriminator loss: -4.820692] [Generator loss: -5.577889]\n",
      "[Epoch 1/1] [Batch 486/938] [Discriminator loss: -4.966998] [Generator loss: -4.819818]\n",
      "[Epoch 1/1] [Batch 491/938] [Discriminator loss: -4.531331] [Generator loss: -4.382471]\n",
      "[Epoch 1/1] [Batch 496/938] [Discriminator loss: -5.507430] [Generator loss: -3.744220]\n",
      "Generator Losses: [251, 256, 261, 266, 271, 276, 281, 286, 291, 296, 301, 306, 311, 316, 321, 326, 331, 336, 341, 346, 351, 356, 361, 366, 371, 376, 381, 386, 391, 396, 401, 406, 411, 416, 421, 426, 431, 436, 441, 446, 451, 456, 461, 466, 471, 476, 481, 486, 491, 496]\n",
      "Discriminator Losses: [251, 256, 261, 266, 271, 276, 281, 286, 291, 296, 301, 306, 311, 316, 321, 326, 331, 336, 341, 346, 351, 356, 361, 366, 371, 376, 381, 386, 391, 396, 401, 406, 411, 416, 421, 426, 431, 436, 441, 446, 451, 456, 461, 466, 471, 476, 481, 486, 491, 496]\n",
      "[Epoch 1/1] [Batch 501/938] [Discriminator loss: -4.902611] [Generator loss: -4.207856]\n",
      "[Epoch 1/1] [Batch 506/938] [Discriminator loss: -4.566736] [Generator loss: -5.691337]\n",
      "[Epoch 1/1] [Batch 511/938] [Discriminator loss: -4.655704] [Generator loss: -4.745415]\n",
      "[Epoch 1/1] [Batch 516/938] [Discriminator loss: -4.958835] [Generator loss: -5.293534]\n",
      "[Epoch 1/1] [Batch 521/938] [Discriminator loss: -3.808360] [Generator loss: -5.365433]\n",
      "[Epoch 1/1] [Batch 526/938] [Discriminator loss: -5.561285] [Generator loss: -2.997404]\n",
      "[Epoch 1/1] [Batch 531/938] [Discriminator loss: -4.239258] [Generator loss: -3.721905]\n",
      "[Epoch 1/1] [Batch 536/938] [Discriminator loss: -3.022562] [Generator loss: -3.280227]\n",
      "[Epoch 1/1] [Batch 541/938] [Discriminator loss: -4.902839] [Generator loss: -4.670744]\n",
      "[Epoch 1/1] [Batch 546/938] [Discriminator loss: -4.043412] [Generator loss: -3.113383]\n",
      "[Epoch 1/1] [Batch 551/938] [Discriminator loss: -3.787127] [Generator loss: -3.675654]\n",
      "[Epoch 1/1] [Batch 556/938] [Discriminator loss: -4.001204] [Generator loss: -2.950710]\n",
      "[Epoch 1/1] [Batch 561/938] [Discriminator loss: -4.659099] [Generator loss: -2.011681]\n",
      "[Epoch 1/1] [Batch 566/938] [Discriminator loss: -5.184416] [Generator loss: -6.090002]\n",
      "[Epoch 1/1] [Batch 571/938] [Discriminator loss: -4.806624] [Generator loss: -3.539384]\n",
      "[Epoch 1/1] [Batch 576/938] [Discriminator loss: -4.595445] [Generator loss: -4.114530]\n",
      "[Epoch 1/1] [Batch 581/938] [Discriminator loss: -4.910225] [Generator loss: -3.279419]\n",
      "[Epoch 1/1] [Batch 586/938] [Discriminator loss: -4.869334] [Generator loss: -3.871515]\n",
      "[Epoch 1/1] [Batch 591/938] [Discriminator loss: -4.839093] [Generator loss: -2.219895]\n",
      "[Epoch 1/1] [Batch 596/938] [Discriminator loss: -5.306614] [Generator loss: -3.823465]\n",
      "[Epoch 1/1] [Batch 601/938] [Discriminator loss: -4.230238] [Generator loss: -2.439993]\n",
      "[Epoch 1/1] [Batch 606/938] [Discriminator loss: -4.029378] [Generator loss: -3.253247]\n",
      "[Epoch 1/1] [Batch 611/938] [Discriminator loss: -5.118361] [Generator loss: -2.099407]\n",
      "[Epoch 1/1] [Batch 616/938] [Discriminator loss: -4.084815] [Generator loss: -2.782127]\n",
      "[Epoch 1/1] [Batch 621/938] [Discriminator loss: -4.598072] [Generator loss: -3.125341]\n",
      "[Epoch 1/1] [Batch 626/938] [Discriminator loss: -3.968797] [Generator loss: -1.850226]\n",
      "[Epoch 1/1] [Batch 631/938] [Discriminator loss: -3.539840] [Generator loss: -0.991031]\n",
      "[Epoch 1/1] [Batch 636/938] [Discriminator loss: -3.829117] [Generator loss: -4.023323]\n",
      "[Epoch 1/1] [Batch 641/938] [Discriminator loss: -3.486340] [Generator loss: -4.316156]\n",
      "[Epoch 1/1] [Batch 646/938] [Discriminator loss: -4.448592] [Generator loss: -1.048465]\n",
      "[Epoch 1/1] [Batch 651/938] [Discriminator loss: -3.417572] [Generator loss: -1.054753]\n",
      "[Epoch 1/1] [Batch 656/938] [Discriminator loss: -3.285434] [Generator loss: 0.227357]\n",
      "[Epoch 1/1] [Batch 661/938] [Discriminator loss: -4.032827] [Generator loss: 1.347787]\n",
      "[Epoch 1/1] [Batch 666/938] [Discriminator loss: -3.951154] [Generator loss: -0.506864]\n",
      "[Epoch 1/1] [Batch 671/938] [Discriminator loss: -5.378003] [Generator loss: -0.667692]\n",
      "[Epoch 1/1] [Batch 676/938] [Discriminator loss: -4.375751] [Generator loss: 0.414237]\n",
      "[Epoch 1/1] [Batch 681/938] [Discriminator loss: -4.176640] [Generator loss: -0.463836]\n",
      "[Epoch 1/1] [Batch 686/938] [Discriminator loss: -4.582613] [Generator loss: -2.034498]\n",
      "[Epoch 1/1] [Batch 691/938] [Discriminator loss: -4.347190] [Generator loss: -1.848264]\n",
      "[Epoch 1/1] [Batch 696/938] [Discriminator loss: -4.994911] [Generator loss: 1.833311]\n",
      "[Epoch 1/1] [Batch 701/938] [Discriminator loss: -5.054123] [Generator loss: 1.413738]\n",
      "[Epoch 1/1] [Batch 706/938] [Discriminator loss: -4.963529] [Generator loss: 0.134386]\n",
      "[Epoch 1/1] [Batch 711/938] [Discriminator loss: -4.494051] [Generator loss: 1.314534]\n",
      "[Epoch 1/1] [Batch 716/938] [Discriminator loss: -5.084445] [Generator loss: -0.038874]\n",
      "[Epoch 1/1] [Batch 721/938] [Discriminator loss: -4.095648] [Generator loss: -1.158632]\n",
      "[Epoch 1/1] [Batch 726/938] [Discriminator loss: -4.649099] [Generator loss: -2.753767]\n",
      "[Epoch 1/1] [Batch 731/938] [Discriminator loss: -4.166159] [Generator loss: -1.898436]\n",
      "[Epoch 1/1] [Batch 736/938] [Discriminator loss: -4.488572] [Generator loss: -1.169728]\n",
      "[Epoch 1/1] [Batch 741/938] [Discriminator loss: -4.705198] [Generator loss: 0.157222]\n",
      "[Epoch 1/1] [Batch 746/938] [Discriminator loss: -3.808105] [Generator loss: -0.720184]\n",
      "Generator Losses: [501, 506, 511, 516, 521, 526, 531, 536, 541, 546, 551, 556, 561, 566, 571, 576, 581, 586, 591, 596, 601, 606, 611, 616, 621, 626, 631, 636, 641, 646, 651, 656, 661, 666, 671, 676, 681, 686, 691, 696, 701, 706, 711, 716, 721, 726, 731, 736, 741, 746]\n",
      "Discriminator Losses: [501, 506, 511, 516, 521, 526, 531, 536, 541, 546, 551, 556, 561, 566, 571, 576, 581, 586, 591, 596, 601, 606, 611, 616, 621, 626, 631, 636, 641, 646, 651, 656, 661, 666, 671, 676, 681, 686, 691, 696, 701, 706, 711, 716, 721, 726, 731, 736, 741, 746]\n",
      "[Epoch 1/1] [Batch 751/938] [Discriminator loss: -3.931079] [Generator loss: -0.302936]\n",
      "[Epoch 1/1] [Batch 756/938] [Discriminator loss: -4.429402] [Generator loss: -2.486367]\n",
      "[Epoch 1/1] [Batch 761/938] [Discriminator loss: -4.838622] [Generator loss: -2.537632]\n",
      "[Epoch 1/1] [Batch 766/938] [Discriminator loss: -4.679147] [Generator loss: -0.642417]\n",
      "[Epoch 1/1] [Batch 771/938] [Discriminator loss: -5.469357] [Generator loss: -0.241866]\n",
      "[Epoch 1/1] [Batch 776/938] [Discriminator loss: -5.430038] [Generator loss: 0.355107]\n",
      "[Epoch 1/1] [Batch 781/938] [Discriminator loss: -4.063769] [Generator loss: -1.438756]\n",
      "[Epoch 1/1] [Batch 786/938] [Discriminator loss: -4.278851] [Generator loss: -0.510509]\n",
      "[Epoch 1/1] [Batch 791/938] [Discriminator loss: -4.682202] [Generator loss: -0.625977]\n",
      "[Epoch 1/1] [Batch 796/938] [Discriminator loss: -3.676571] [Generator loss: -1.130382]\n",
      "[Epoch 1/1] [Batch 801/938] [Discriminator loss: -4.365088] [Generator loss: -1.766698]\n",
      "[Epoch 1/1] [Batch 806/938] [Discriminator loss: -3.690287] [Generator loss: -1.683838]\n",
      "[Epoch 1/1] [Batch 811/938] [Discriminator loss: -4.201264] [Generator loss: -0.547400]\n",
      "[Epoch 1/1] [Batch 816/938] [Discriminator loss: -3.803350] [Generator loss: -1.136569]\n",
      "[Epoch 1/1] [Batch 821/938] [Discriminator loss: -3.813011] [Generator loss: -0.041157]\n",
      "[Epoch 1/1] [Batch 826/938] [Discriminator loss: -4.143364] [Generator loss: 0.455435]\n",
      "[Epoch 1/1] [Batch 831/938] [Discriminator loss: -4.250964] [Generator loss: 1.371084]\n",
      "[Epoch 1/1] [Batch 836/938] [Discriminator loss: -4.249441] [Generator loss: -0.294742]\n",
      "[Epoch 1/1] [Batch 841/938] [Discriminator loss: -3.680128] [Generator loss: -1.554842]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1] [Batch 846/938] [Discriminator loss: -4.375093] [Generator loss: -1.649229]\n",
      "[Epoch 1/1] [Batch 851/938] [Discriminator loss: -4.230699] [Generator loss: -0.990210]\n",
      "[Epoch 1/1] [Batch 856/938] [Discriminator loss: -4.348237] [Generator loss: -0.632761]\n",
      "[Epoch 1/1] [Batch 861/938] [Discriminator loss: -4.332053] [Generator loss: 0.184667]\n",
      "[Epoch 1/1] [Batch 866/938] [Discriminator loss: -5.035052] [Generator loss: 2.041342]\n",
      "[Epoch 1/1] [Batch 871/938] [Discriminator loss: -4.179540] [Generator loss: -0.856347]\n",
      "[Epoch 1/1] [Batch 876/938] [Discriminator loss: -4.913606] [Generator loss: 1.628767]\n",
      "[Epoch 1/1] [Batch 881/938] [Discriminator loss: -4.620762] [Generator loss: 0.040448]\n",
      "[Epoch 1/1] [Batch 886/938] [Discriminator loss: -4.622988] [Generator loss: 0.255912]\n",
      "[Epoch 1/1] [Batch 891/938] [Discriminator loss: -4.235046] [Generator loss: 0.629328]\n",
      "[Epoch 1/1] [Batch 896/938] [Discriminator loss: -4.483991] [Generator loss: 1.916887]\n",
      "[Epoch 1/1] [Batch 901/938] [Discriminator loss: -4.576482] [Generator loss: 1.157647]\n",
      "[Epoch 1/1] [Batch 906/938] [Discriminator loss: -4.656521] [Generator loss: 2.409402]\n",
      "[Epoch 1/1] [Batch 911/938] [Discriminator loss: -4.326430] [Generator loss: 0.139623]\n",
      "[Epoch 1/1] [Batch 916/938] [Discriminator loss: -4.360120] [Generator loss: -0.602467]\n",
      "[Epoch 1/1] [Batch 921/938] [Discriminator loss: -3.792665] [Generator loss: 0.335256]\n",
      "[Epoch 1/1] [Batch 926/938] [Discriminator loss: -4.231719] [Generator loss: 0.407399]\n",
      "[Epoch 1/1] [Batch 931/938] [Discriminator loss: -3.995256] [Generator loss: -0.548892]\n",
      "[Epoch 1/1] [Batch 936/938] [Discriminator loss: -4.700679] [Generator loss: 0.459752]\n"
     ]
    }
   ],
   "source": [
    "results: Results = Results(\"wgan\")\n",
    "\n",
    "train: TrainWGan = TrainWGan(params, results.loss_updated_callback)\n",
    "train.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_losses: {} = results.generator_losses\n",
    "discriminator_losses: {} = results.discriminator_losses\n",
    "last_generator: torch.nn.Module = results.last_generator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0.02092120796442032, 6: 0.005333012901246548, 11: -0.05641145259141922, 16: -0.2138962298631668, 21: -0.46380338072776794, 26: -0.6581395864486694, 31: -0.8725836277008057, 36: -1.0839707851409912, 41: -1.29779052734375, 46: -1.5633106231689453, 51: -1.8385038375854492, 56: -2.116753101348877, 61: -2.3850696086883545, 66: -2.7478296756744385, 71: -3.15753173828125, 76: -3.591050386428833, 81: -3.997032642364502, 86: -4.581509113311768, 91: -5.021251678466797, 96: -5.476865768432617, 101: -6.199121952056885, 106: -6.495793342590332, 111: -7.617455959320068, 116: -7.995965957641602, 121: -9.020689010620117, 126: -9.48087215423584, 131: -9.792229652404785, 136: -10.776042938232422, 141: -11.275318145751953, 146: -11.763315200805664, 151: -12.502201080322266, 156: -11.45547103881836, 161: -12.25210952758789, 166: -11.561017990112305, 171: -11.795769691467285, 176: -11.001579284667969, 181: -11.628725051879883, 186: -12.783065795898438, 191: -13.074605941772461, 196: -12.407998085021973, 201: -11.586868286132812, 206: -13.27855110168457, 211: -13.56090259552002, 216: -13.683098793029785, 221: -13.872068405151367, 226: -13.751344680786133, 231: -12.626861572265625, 236: -11.174473762512207, 241: -8.578096389770508, 246: -8.837586402893066, 251: -9.155350685119629, 256: -8.288225173950195, 261: -10.105125427246094, 266: -9.235358238220215, 271: -9.461564064025879, 276: -9.853411674499512, 281: -10.420106887817383, 286: -10.316218376159668, 291: -11.191254615783691, 296: -9.846500396728516, 301: -9.28114128112793, 306: -9.61488151550293, 311: -8.756280899047852, 316: -7.888828277587891, 321: -5.199209213256836, 326: -4.4123711585998535, 331: -3.8677825927734375, 336: 0.09879747033119202, 341: 2.2952895164489746, 346: 5.668642520904541, 351: 6.935976028442383, 356: 3.8876073360443115, 361: 1.8533105850219727, 366: 2.6914851665496826, 371: 0.9063538312911987, 376: -0.9515001773834229, 381: -2.0622589588165283, 386: 0.4712025225162506, 391: -1.2780474424362183, 396: -2.777204990386963, 401: -2.459054708480835, 406: -0.36010897159576416, 411: -2.3971893787384033, 416: -3.1984128952026367, 421: -2.7959227561950684, 426: 1.2042198181152344, 431: -2.6121137142181396, 436: -1.9366297721862793, 441: -2.401664972305298, 446: -2.723452568054199, 451: -1.5954517126083374, 456: -1.715222716331482, 461: -1.2588748931884766, 466: -4.470120906829834, 471: -4.465357303619385, 476: -3.0488028526306152, 481: -5.577889442443848, 486: -4.819818496704102, 491: -4.382471084594727, 496: -3.74422025680542, 501: -4.207856178283691, 506: -5.691336631774902, 511: -4.745414733886719, 516: -5.293533802032471, 521: -5.365433216094971, 526: -2.997404098510742, 531: -3.721905469894409, 536: -3.280226945877075, 541: -4.6707444190979, 546: -3.1133828163146973, 551: -3.675654411315918, 556: -2.9507102966308594, 561: -2.0116806030273438, 566: -6.090002059936523, 571: -3.539384365081787, 576: -4.114530086517334, 581: -3.279419183731079, 586: -3.8715147972106934, 591: -2.219895362854004, 596: -3.8234646320343018, 601: -2.439993381500244, 606: -3.2532474994659424, 611: -2.0994067192077637, 616: -2.7821266651153564, 621: -3.1253411769866943, 626: -1.8502259254455566, 631: -0.991030752658844, 636: -4.023323059082031, 641: -4.316156387329102, 646: -1.0484650135040283, 651: -1.0547525882720947, 656: 0.22735707461833954, 661: 1.3477869033813477, 666: -0.5068637132644653, 671: -0.6676918268203735, 676: 0.4142369329929352, 681: -0.4638358950614929, 686: -2.034498453140259, 691: -1.8482636213302612, 696: 1.8333114385604858, 701: 1.4137382507324219, 706: 0.13438640534877777, 711: 1.3145335912704468, 716: -0.038874223828315735, 721: -1.1586318016052246, 726: -2.753767251968384, 731: -1.898436188697815, 736: -1.1697275638580322, 741: 0.15722182393074036, 746: -0.7201842665672302, 751: -0.3029363751411438, 756: -2.4863667488098145, 761: -2.5376319885253906, 766: -0.6424170732498169, 771: -0.24186649918556213, 776: 0.35510674118995667, 781: -1.4387558698654175, 786: -0.5105090141296387, 791: -0.6259772181510925, 796: -1.1303822994232178, 801: -1.7666982412338257, 806: -1.6838375329971313, 811: -0.547400176525116, 816: -1.1365689039230347, 821: -0.04115662723779678, 826: 0.4554348886013031, 831: 1.3710836172103882, 836: -0.29474151134490967, 841: -1.5548421144485474, 846: -1.6492291688919067, 851: -0.9902102947235107, 856: -0.6327607035636902, 861: 0.18466714024543762, 866: 2.041342258453369, 871: -0.8563473224639893, 876: 1.628767490386963, 881: 0.04044800251722336, 886: 0.25591224431991577, 891: 0.629327654838562, 896: 1.9168869256973267, 901: 1.157646894454956, 906: 2.409402370452881, 911: 0.13962286710739136, 916: -0.6024665832519531, 921: 0.3352564573287964, 926: 0.4073992669582367, 931: -0.5488916635513306, 936: 0.45975157618522644}\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title(\"WGAN_FASHION_MNIST\")\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "x_values: [] = []\n",
    "y_values: [] = []\n",
    "    \n",
    "\n",
    "    \n",
    "plt.plot(np.array(train_values), 'r', label='Train')\n",
    "plt.xticks(np.arange(len(train_values)), np.arange(1, len(train_values)+1))\n",
    "    \n",
    "plt.plot(np.array(test_values), 'b', label='Test')\n",
    "plt.xticks(np.arange(len(test_values)), np.arange(1, len(test_values)+1))\n",
    "    \n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_noise: Tensor = torch.randn(2, 100)\n",
    "if torch.cuda.is_available():\n",
    "    fixed_noise = fixed_noise.cuda()\n",
    "\n",
    "generated_image = last_generator(fixed_noise)\n",
    "image_path_1 = \"results/wgan_1.png\"\n",
    "image_path_2 = \"results/wgan_2.png\"\n",
    "save_image(generated_image.data[0], image_path_1, nrow=2, normalize=True)\n",
    "save_image(generated_image.data[1], image_path_2, nrow=2, normalize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}